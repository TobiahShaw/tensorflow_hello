{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 深入MNIST\n\n这里，我们使用更加方便的InteractiveSession类。通过它，你可以更加灵活地构建你的代码。它能让你在运行图的时候，插入一些计算图，这些计算图是由某些操作(operations)构成的。这对于使用IPython、jupyter note等的人们来说非常便利。如果你没有使用InteractiveSession，那么你需要在启动session之前构建整个计算图，然后启动该计算图。\n\n## 为什么使用计算图，而不是直接计算\n\n为了在Python中进行高效的数值计算，我们通常会使用像NumPy一类的库，将一些诸如矩阵乘法的耗时操作在Python环境的外部来计算，这些计算通常会通过其它语言并用更为高效的代码来实现。\n\n但遗憾的是，每一个操作切换回Python环境时仍需要不小的开销。如果你想在GPU或者分布式环境中计算时，这一开销更加可怖，这一开销主要可能是用来进行数据迁移。\n\n因此Python代码的目的是用来构建这个可以在外部运行的计算图，以及安排计算图的哪一部分应该被运行。"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nimport py_code.input_data as input_data",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)",
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "WARNING:tensorflow:From <ipython-input-2-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\nWARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease write your own downloading logic.\nWARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\nExtracting MNIST_data/train-images-idx3-ubyte.gz\nWARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\nWARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.one_hot on tensors.\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\nWARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "sess = tf.InteractiveSession()",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 占位符\nx = tf.placeholder(float, [None, 784])\ny_ = tf.placeholder(float, [None, 10])",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 变量\nW = tf.Variable(tf.zeros([784, 10]))\nb = tf.Variable(tf.zeros([10]))",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "sess.run(tf.global_variables_initializer())",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 类别预测\ny = tf.nn.softmax(tf.matmul(x, W) + b)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 损失函数\ncross_entropy = -tf.reduce_sum(y_*tf.log(y))",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 训练模型\ntrain_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "for i in range(1000):\n  batch = mnist.train.next_batch(50)\n  train_step.run(feed_dict={x: batch[0], y_: batch[1]})",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 评估模型\ncorrect_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))",
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "0.9152\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "可以看到和上一节差不多的步骤得到了，和上一节差不多的结果"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 构建一个多层卷积网络"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 权重初始化\n\n这里我们加入一些噪声，用以打破对称性，以及避免0梯度"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "def weight_variable(shape):\n  initial = tf.truncated_normal(shape, stddev=0.1)\n  return tf.Variable(initial)\n\ndef bias_variable(shape):\n  initial = tf.constant(0.1, shape=shape)\n  return tf.Variable(initial)",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 卷积和池化\n\n我们的卷积使用1步长（stride size），0边距（padding size）的模板，保证输出和输入是同一个大小。我们的池化用简单传统的2x2大小的模板做max pooling。"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "def conv2d(x, W):\n  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\ndef max_pool_2x2(x):\n  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                        strides=[1, 2, 2, 1], padding='SAME')",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 第一层卷积"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "W_conv1 = weight_variable([5, 5, 1, 32])\nb_conv1 = bias_variable([32])",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "x_image = tf.reshape(x, [-1,28,28,1])",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\nh_pool1 = max_pool_2x2(h_conv1)",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 第二层卷积"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "W_conv2 = weight_variable([5, 5, 32, 64])\nb_conv2 = bias_variable([64])\n\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\nh_pool2 = max_pool_2x2(h_conv2)",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 密集连接层"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "W_fc1 = weight_variable([7 * 7 * 64, 1024])\nb_fc1 = bias_variable([1024])\n\nh_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Dropout"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "keep_prob = tf.placeholder(\"float\")\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 输出层"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "W_fc2 = weight_variable([1024, 10])\nb_fc2 = bias_variable([10])\n\ny_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 训练和评估模型"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\ncorrect_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\nsess.run(tf.global_variables_initializer())\nfor i in range(4000):\n  batch = mnist.train.next_batch(50)\n  if i%100 == 0:\n    train_accuracy = accuracy.eval(feed_dict={\n        x:batch[0], y_: batch[1], keep_prob: 1.0})\n    print (\"step %d, training accuracy %g\"%(i, train_accuracy))\n  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n\nprint (\"test accuracy %g\"%accuracy.eval(feed_dict={\n    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))",
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "step 0, training accuracy 0.08\nstep 100, training accuracy 0.74\nstep 200, training accuracy 0.94\nstep 300, training accuracy 0.94\nstep 400, training accuracy 0.92\nstep 500, training accuracy 0.86\nstep 600, training accuracy 0.96\nstep 700, training accuracy 0.98\nstep 800, training accuracy 1\nstep 900, training accuracy 0.94\nstep 1000, training accuracy 0.98\nstep 1100, training accuracy 0.96\nstep 1200, training accuracy 0.94\nstep 1300, training accuracy 0.96\nstep 1400, training accuracy 0.96\nstep 1500, training accuracy 0.94\nstep 1600, training accuracy 0.98\nstep 1700, training accuracy 0.98\nstep 1800, training accuracy 0.96\nstep 1900, training accuracy 0.98\nstep 2000, training accuracy 0.98\nstep 2100, training accuracy 0.96\nstep 2200, training accuracy 0.92\nstep 2300, training accuracy 0.98\nstep 2400, training accuracy 0.96\nstep 2500, training accuracy 0.98\nstep 2600, training accuracy 0.98\nstep 2700, training accuracy 0.96\nstep 2800, training accuracy 0.94\nstep 2900, training accuracy 1\nstep 3000, training accuracy 0.98\nstep 3100, training accuracy 1\nstep 3200, training accuracy 0.98\nstep 3300, training accuracy 1\nstep 3400, training accuracy 1\nstep 3500, training accuracy 0.98\nstep 3600, training accuracy 0.98\nstep 3700, training accuracy 0.98\nstep 3800, training accuracy 0.96\nstep 3900, training accuracy 1\ntest accuracy 0.9826\n"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}